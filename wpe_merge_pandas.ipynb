{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import nan\n",
    "import requests\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_filepath = \"test-data.csv\"\n",
    "output_filepath = \"out.csv\"\n",
    "\n",
    "if not os.path.exists(input_filepath):\n",
    "    print(f\"ERROR - input filepath {input_filepath} does not exist\")\n",
    "\n",
    "path_to_output = output_filepath.rpartition(\"/\")[0]\n",
    "if path_to_output != \"\":\n",
    "    os.makedirs(path_to_output, exist_ok=True)\n",
    "\n",
    "if input_filepath[-4:] != \".csv\" or output_filepath[-4:] != \".csv\": \n",
    "    print(\"ERROR - filepaths must be valid csv files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing with pandas assuming accurate headers and reasonable size of data\n",
    "raw_data = pd.read_csv(input_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some failure testing, do not include in live\n",
    "raw_data = raw_data.append(pd.read_csv(\"fail_tests.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account ID</th>\n",
       "      <th>Account Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Created On</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>314159</td>\n",
       "      <td>superman</td>\n",
       "      <td>Ka-el</td>\n",
       "      <td>1/12/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271</td>\n",
       "      <td>batman</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>11/19/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8675309</td>\n",
       "      <td>hulk</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>2/22/99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99999</td>\n",
       "      <td>batgirl</td>\n",
       "      <td>Yvonne</td>\n",
       "      <td>3/5/13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asdf</td>\n",
       "      <td>thisEntryShouldBeDeleted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>thisEntryShouldBeDeleted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whenever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>thisEntryShouldBeDeleted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/4/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271</td>\n",
       "      <td>thisEntryShouldBeDeleted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/19/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Account ID               Account Name First Name Created On\n",
       "0     314159                   superman      Ka-el    1/12/13\n",
       "1        271                     batman      Bruce   11/19/16\n",
       "2    8675309                       hulk      Bruce    2/22/99\n",
       "3      99999                    batgirl     Yvonne     3/5/13\n",
       "0       asdf   thisEntryShouldBeDeleted        NaN       None\n",
       "1        NaN   thisEntryShouldBeDeleted        NaN   whenever\n",
       "2        NaN   thisEntryShouldBeDeleted        NaN     2/4/12\n",
       "3        271   thisEntryShouldBeDeleted        NaN   11/19/16\n",
       "4         21                        NaN        NaN        NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean data, set types, remove nan account_ids, create columns needed for output\n",
    "def data_cleaner(raw_data):\n",
    "    clean_data = raw_data\n",
    "\n",
    "    # might not necessarily want to assume the type of the Account ID, \n",
    "    # but definitely dont want .0s on the end for api query\n",
    "    # coercing yields NaNs where errors occur which are filtered later\n",
    "    clean_data[\"Account ID\"] = pd.to_numeric(clean_data[\"Account ID\"], errors='coerce')\\\n",
    "        .astype(\"int\", errors='ignore')#, downcast=\"integer\")\n",
    "    # set as datetime to check validity and match \"Status Set On\" data\n",
    "    clean_data[\"Created On\"] = pd.to_datetime(clean_data[\"Created On\"], errors='coerce')\n",
    "\n",
    "    #unneccesary column\n",
    "    clean_data = clean_data.drop([\"Account Name\"], axis=1)\n",
    "\n",
    "    # clean data, create contract account_id is unique integer not na, and one other property must be non na.\n",
    "    clean_data = clean_data.dropna(axis = 0, how=\"any\",subset=[\"Account ID\"]) # must have Account ID\n",
    "    clean_data = clean_data.dropna(axis = 0, how=\"all\",subset=[\"First Name\",\"Created On\"]) # account with all empty data\n",
    "    clean_data[\"Account ID\"] = clean_data[\"Account ID\"].astype(\"int\", errors='ignore')\n",
    "\n",
    "    # create columns for output\n",
    "    try:\n",
    "        clean_data[\"Status\"]\n",
    "    except:\n",
    "        clean_data[\"Status\"] = nan\n",
    "        clean_data[\"Status Set On\"] = nan\n",
    "\n",
    "    # account id acts as index and must be unique\n",
    "    clean_data = clean_data.drop_duplicates(subset=[\"Account ID\"])\n",
    "    clean_data = clean_data.set_index(\"Account ID\")\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query accounts/account_id and determine if non-error json is returned\n",
    "# returns validity of response and the response\n",
    "def query(account_id):\n",
    "    is_valid = True\n",
    "    returned_dict = {}\n",
    "    request = requests.get(\"http://interview.wpengine.io/v1/accounts/\" + str(account_id))\n",
    "    try: # check parseable response\n",
    "        returned_dict = request.json()\n",
    "    except ValueError:\n",
    "        print(\"response not json parsable for account id \" + str(account_id))\n",
    "        is_valid = False\n",
    "    try: # check not error message\n",
    "        print(str(account_id) + \" \" + returned_dict[\"details\"])\n",
    "        is_valid = False\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return is_valid, returned_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# query for each account_id and merge is_valid  \n",
    "def query_and_merge_all(df_in):\n",
    "    \n",
    "    df_out = df_in\n",
    "    total_ids = df_out.index.size\n",
    "    \n",
    "    for index, account_id in enumerate(df_out.index.tolist()):\n",
    "        is_valid, returned_dict = query(account_id)\n",
    "        \n",
    "        # go ahead and try again once after backoff in case of connection problem, \n",
    "        # having problem with first query being denied bc of network problems\n",
    "        if not is_valid: \n",
    "            time.sleep(1)\n",
    "            is_valid, returned_dict = query(account_id)\n",
    "\n",
    "        if is_valid: #set new df_out values\n",
    "            try:\n",
    "                # set Status Set On to response's created_on value for account_id\n",
    "                # could introduce check for status in set (\"good\", \"bad\", \"\")\n",
    "                df_out.loc[account_id, \"Status\"] = returned_dict[\"status\"]\n",
    "                print(f\"processed id - {account_id} \", end=\"\\t\")\n",
    "            except KeyError:\n",
    "                print(f\"no status data included for account id - {account_id}\", end=\"\\t\")\n",
    "            \n",
    "            # only try and set status date if status successfully set\n",
    "            try:\n",
    "                # set Status Set On to response's created_on value for account_id\n",
    "                # here choosing to write nan in event of bad date\n",
    "                df_out.loc[account_id, \"Status Set On\"] = pd.to_datetime(returned_dict[\"created_on\"], errors='coerce') \n",
    "            except KeyError:\n",
    "                print(f\"no created_on date included for account id - {account_id}\", end=\"\\t\")\n",
    "        print(\"--\" + str(index+1) + \"/\" + str(total_ids))\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed id - 314159 \t--1/4\n",
      "processed id - 271 \t--2/4\n",
      "processed id - 8675309 \t--3/4\n",
      "processed id - 99999 \t--4/4\n"
     ]
    }
   ],
   "source": [
    "df = data_cleaner(raw_data)\n",
    "df = query_and_merge_all(df)\n",
    "df[\"Status Set On\"] = pd.to_datetime(df[\"Status Set On\"], errors='coerce') #drops seconds\n",
    "df.to_csv(output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
